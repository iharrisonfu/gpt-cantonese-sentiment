{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0a2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "from opencc import OpenCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce597313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/sentiment_analysis_latest.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e779eb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     3267\n",
       "negative    1943\n",
       "positive     959\n",
       "Name: sentiment_label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09a86c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversationId</th>\n",
       "      <th>datetime</th>\n",
       "      <th>from_whom</th>\n",
       "      <th>msg_replace</th>\n",
       "      <th>pp</th>\n",
       "      <th>max_pp</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>543101a7-3c19-4fa5-9c9c-70f5a1b86c18</td>\n",
       "      <td>2021-11-27 21:02:05</td>\n",
       "      <td>c:</td>\n",
       "      <td>其實我感覺到你對課堂嘅重視..會好用心準備..校長嘅說話都確實難免令人耿耿於懷 幾個月其實都...</td>\n",
       "      <td>24</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>734dfb95-747a-4c3e-bd6a-d90bab176628</td>\n",
       "      <td>2023-03-31 01:10:15</td>\n",
       "      <td>c:</td>\n",
       "      <td>我聽到嘅[***name***]對於4年入面自己嘅表現都好後悔，覺得係分手嘅主因 但係我見到...</td>\n",
       "      <td>12</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>50f95550-8d13-4973-b576-8f38fe5e3d08</td>\n",
       "      <td>2022-01-09 03:28:11</td>\n",
       "      <td>c:</td>\n",
       "      <td>好多謝你今日肯花時間同我分享咁多，雖然我地未必可以諗到一個完美嘅解決方法,不過希望你今日傾過...</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>17886c87-016c-480a-85fe-99362878a940</td>\n",
       "      <td>2020-10-06 03:40:24</td>\n",
       "      <td>c:</td>\n",
       "      <td>你響屋企感覺到背叛同敵意，其實都對你造成好大傷害，咁呢一刻離開呢個家，都係一個機會比你可以抖...</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>e7cb758c-97c2-4596-a230-4e78adb9fc72</td>\n",
       "      <td>2022-11-22 08:42:47</td>\n",
       "      <td>c:</td>\n",
       "      <td>嗯嗯 可能[***name***]都習慣左去諗多d~ 都係出於好意~ 為未來負責任~ 平時如...</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>5347794a-d26c-4a62-9629-343fe80d6ecd</td>\n",
       "      <td>2023-01-12 23:08:16.400000</td>\n",
       "      <td>c:</td>\n",
       "      <td>唔緊要呢～我地好free</td>\n",
       "      <td>90</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            conversationId                    datetime  \\\n",
       "4288  543101a7-3c19-4fa5-9c9c-70f5a1b86c18         2021-11-27 21:02:05   \n",
       "5792  734dfb95-747a-4c3e-bd6a-d90bab176628         2023-03-31 01:10:15   \n",
       "581   50f95550-8d13-4973-b576-8f38fe5e3d08         2022-01-09 03:28:11   \n",
       "2323  17886c87-016c-480a-85fe-99362878a940         2020-10-06 03:40:24   \n",
       "2045  e7cb758c-97c2-4596-a230-4e78adb9fc72         2022-11-22 08:42:47   \n",
       "6154  5347794a-d26c-4a62-9629-343fe80d6ecd  2023-01-12 23:08:16.400000   \n",
       "\n",
       "     from_whom                                        msg_replace  pp  max_pp  \\\n",
       "4288        c:  其實我感覺到你對課堂嘅重視..會好用心準備..校長嘅說話都確實難免令人耿耿於懷 幾個月其實都...  24      59   \n",
       "5792        c:  我聽到嘅[***name***]對於4年入面自己嘅表現都好後悔，覺得係分手嘅主因 但係我見到...  12      73   \n",
       "581        c:   好多謝你今日肯花時間同我分享咁多，雖然我地未必可以諗到一個完美嘅解決方法,不過希望你今日傾過...  82      85   \n",
       "2323       c:   你響屋企感覺到背叛同敵意，其實都對你造成好大傷害，咁呢一刻離開呢個家，都係一個機會比你可以抖...  16      77   \n",
       "2045       c:   嗯嗯 可能[***name***]都習慣左去諗多d~ 都係出於好意~ 為未來負責任~ 平時如...  38      49   \n",
       "6154        c:                                       唔緊要呢～我地好free  90     104   \n",
       "\n",
       "      sentiment_label  \n",
       "4288                2  \n",
       "5792                2  \n",
       "581                 2  \n",
       "2323                2  \n",
       "2045                2  \n",
       "6154                2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['sentiment_label'] == 2)].sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62941e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_tag = {'positive':2, 'neutral':1, 'negative':0}\n",
    "df['sentiment_label']= df['sentiment_label'].replace(replace_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f6cbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3267\n",
       "0    1943\n",
       "2     959\n",
       "Name: sentiment_label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebcd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msg = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad22935",
   "metadata": {},
   "source": [
    "# tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93f1813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from pycantonese.word_segmentation import Segmenter\n",
    "import pycantonese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30917c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\Harrison\\Documents\\HKU\\paper\\GPT_sentiment_analysis\\supplementary_material\\data\\tokenization_dict\\dict.txt ...\n",
      "Loading model from cache C:\\Users\\Harrison\\AppData\\Local\\Temp\\jieba.uca32d7fd4479c948cd6f929a868b2453.cache\n",
      "Loading model cost 0.648 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# load self-defined tokenization dictionary\n",
    "jieba.set_dictionary('../data/tokenization_dict/dict.txt')\n",
    "jieba.load_userdict('../data/tokenization_dict/hk_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6ef9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2hk=[]\n",
    "converter = OpenCC('s2hk.json')\n",
    "for i in range(len(df_msg)):\n",
    "    s2hk.append(converter.convert(df_msg.msg_replace[i]))\n",
    "df_msg['msg_replace']=s2hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0a90022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords\n",
    "stop_words=['乜','個','嗰','吖','啦','又','呀','咗','咁','呢','咩','哦','哩','啲','啊','喎','嗯','噢','喔',\n",
    "            '果','係','左','先','架','㗎','噶','嘎','嘅','既','嘢','噉','即','同','都','有','冇','的','黎','嚟',\n",
    "            '啦', '啵', '喺', '嗱', '嘅', '噃', '咁', '噉', '噓', '唔', '嘛', '咩', '嘢', '啊', '嗚', '嘻', '啫',\n",
    "            '啱', '添', '喇', '甘', '咯', '啊']\n",
    "\n",
    "cn_stopwords=list(pd.read_csv(\"../data/stopwords/cn_stopwords.txt\").to_numpy().squeeze())\n",
    "scu_stopwords=list(pd.read_csv(\"../data/stopwords/scu_stopwords.txt\").to_numpy().squeeze())\n",
    "traditional_cn_stopwords = []\n",
    "traditional_scu_stopwords = []\n",
    "converter = OpenCC('s2hk.json')\n",
    "for i in range(len(cn_stopwords)):\n",
    "    traditional_cn_stopwords.append(converter.convert(cn_stopwords[i]))\n",
    "for i in range(len(scu_stopwords)):\n",
    "    traditional_scu_stopwords.append(converter.convert(scu_stopwords[i]))\n",
    "    \n",
    "pycantonese_stopwords=list(pycantonese.stop_words())\n",
    "\n",
    "stop_words_total = stop_words + traditional_cn_stopwords + traditional_scu_stopwords + pycantonese_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5623c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "speech_list = list(df_msg['msg_replace'])\n",
    "rule = re.compile(r\"[^\\u4e00-\\u9fa5]\")\n",
    "speech_list = [list(jieba.cut(rule.sub('', speech))) for speech in speech_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f28a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "for idx, speech in enumerate(speech_list):\n",
    "    speech_list[idx] = ' '.join([word for word in speech if word.strip() not in stop_words_total])\n",
    "\n",
    "df_msg['msg_token'] = speech_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac3127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msg['msg_token'] = [i.split(' ') for i in df_msg['msg_token']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48551cfa",
   "metadata": {},
   "source": [
    "# construct embedding layer with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "242e5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cb48915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 8914 different tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 4096\n",
    "\n",
    "df_msg['msg_token'] = df_msg['msg_token'].fillna(\"\")\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df_msg['msg_token'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('There are totally %s different tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f434ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('../word2vec_embedding/openup_word2vec_20231001.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5fc26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_message_vector(msg, model):\n",
    "    word_vectors = [model.wv[word] for word in msg if word in model.wv.key_to_index]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    message_vector = np.mean(word_vectors, axis=0)\n",
    "    return message_vector\n",
    "\n",
    "# Get the vector representation of each message\n",
    "message_vectors = np.array([get_message_vector(msg, w2v_model) for msg in df_msg['msg_token']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "418b47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_msg['sentiment_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c0ace45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4935, 100) (4935,)\n",
      "(1234, 100) (1234,)\n"
     ]
    }
   ],
   "source": [
    "# split training and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(message_vectors, labels, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67094f6",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f65cd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d86fabbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       380\n",
      "           1       0.68      0.81      0.74       666\n",
      "           2       0.55      0.27      0.36       188\n",
      "\n",
      "    accuracy                           0.66      1234\n",
      "   macro avg       0.63      0.56      0.57      1234\n",
      "weighted avg       0.65      0.66      0.64      1234\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, Y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(Y_test, lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "075324c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65957447, 0.65248227, 0.63424519, 0.68490375, 0.64944276])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lg_acc = cross_val_score(estimator=lr_model, X=X_train, y=Y_train, cv=5, n_jobs=-1)\n",
    "model_lg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "286de33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.660453808752026\n"
     ]
    }
   ],
   "source": [
    "print(lr_model.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "690b4dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.660453808752026"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "Y_pred = lr_model.predict(X_test)\n",
    "\n",
    "f1_score(Y_test, Y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6abc1c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5725007300768382"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, Y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fab6d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6440150834186715"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, Y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27632b7",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae8ab2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fafe62df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61       380\n",
      "           1       0.65      0.87      0.75       666\n",
      "           2       0.82      0.07      0.14       188\n",
      "\n",
      "    accuracy                           0.66      1234\n",
      "   macro avg       0.71      0.50      0.50      1234\n",
      "weighted avg       0.68      0.66      0.61      1234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_model = svm.SVC(C=0.1, kernel='rbf')\n",
    "svm_model.fit(X_train, Y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(Y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "785369ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67173252, 0.67071935, 0.65552178, 0.67882472, 0.66160081])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm_acc = cross_val_score(estimator=svm_model, X=X_train, y=Y_train, cv=5, n_jobs=-1)\n",
    "model_svm_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38f4190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6564019448946515\n"
     ]
    }
   ],
   "source": [
    "print(svm_model.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ad4aa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6564019448946515"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "f1_score(Y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d89dc3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4973258246045725"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221feda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098bf29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
