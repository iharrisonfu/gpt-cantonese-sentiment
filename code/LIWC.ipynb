{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de7d6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting liwc\n",
      "  Downloading liwc-0.5.0-py2.py3-none-any.whl (5.1 kB)\n",
      "Installing collected packages: liwc\n",
      "Successfully installed liwc-0.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8279c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import liwc\n",
    "import jieba\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f733cf",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b897e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/sentiment_analysis_latest_final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7100b5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3267\n",
       "0    1943\n",
       "2     959\n",
       "Name: sentiment_label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e3032",
   "metadata": {},
   "source": [
    "# tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da05e801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\Harrison\\Documents\\HKU\\paper\\GPT_sentiment_analysis\\supplementary_material\\data\\tokenization_dict\\dict.txt ...\n",
      "Loading model from cache C:\\Users\\Harrison\\AppData\\Local\\Temp\\jieba.uca32d7fd4479c948cd6f929a868b2453.cache\n",
      "Loading model cost 0.862 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# load self-defined tokenization dictionary\n",
    "jieba.set_dictionary('../data/tokenization_dict/dict.txt')\n",
    "jieba.load_userdict('../data/tokenization_dict/hk_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6da17fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep Chinese char, and then remove stopwords\n",
    "speech_list = list(df['msg_replace'])\n",
    "rule = re.compile(r\"[^\\u4e00-\\u9fa5]\")\n",
    "speech_list = [list(jieba.cut(rule.sub('', speech))) for speech in speech_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a9c3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['msg_token'] = speech_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1501831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_categories(lines):\n",
    "    \"\"\"\n",
    "    Read (category_id, category_name) pairs from the categories section.\n",
    "    Each line consists of an integer followed a tab and then the category name.\n",
    "    This section is separated from the lexicon by a line consisting of a single \"%\".\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line == \"%\":\n",
    "            return\n",
    "        # ignore non-matching groups of categories\n",
    "        if \"\\t\" in line:\n",
    "            category_id, category_name = line.split(\"\\t\", 1)\n",
    "            yield category_id, category_name\n",
    "\n",
    "\n",
    "def _parse_lexicon(lines, category_mapping):\n",
    "    \"\"\"\n",
    "    Read (match_expression, category_names) pairs from the lexicon section.\n",
    "    Each line consists of a match expression followed by a tab and then one or more\n",
    "    tab-separated integers, which are mapped to category names using `category_mapping`.\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        parts = line.split(\"\\t\")\n",
    "        yield parts[0], [category_mapping[category_id] for category_id in parts[1:]]\n",
    "\n",
    "\n",
    "def read_dic(filepath):\n",
    "    \"\"\"\n",
    "    Reads a LIWC lexicon from a file in the .dic format, returning a tuple of\n",
    "    (lexicon, category_names), where:\n",
    "    * `lexicon` is a dict mapping string patterns to lists of category names\n",
    "    * `category_names` is a list of category names (as strings)\n",
    "    \"\"\"\n",
    "    with open(filepath, encoding='utf_8_sig') as lines:\n",
    "        # read up to first \"%\" (should be very first line of file)\n",
    "        for line in lines:\n",
    "            if line.strip() == \"%\":\n",
    "                break\n",
    "        # read categories (a mapping from integer string to category name)\n",
    "        category_mapping = dict(_parse_categories(lines))\n",
    "        # read lexicon (a mapping from matching string to a list of category names)\n",
    "        lexicon = dict(_parse_lexicon(lines, category_mapping))\n",
    "    return lexicon, list(category_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "510c56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse, category_names = read_dic('../data/Traditional_Chinese_LIWC2015_Dictionary_v1.5.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ddeb9db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['function (Function Words)',\n",
       " 'pronoun (Pronouns)',\n",
       " 'ppron (Personal Pronouns)',\n",
       " 'i (I)',\n",
       " 'we (We)',\n",
       " 'you (You)',\n",
       " 'shehe (SheHe)',\n",
       " 'they (They)',\n",
       " 'youpl (youpl)',\n",
       " 'ipron (Impersonal Pronouns)',\n",
       " 'prep (Prepositions)',\n",
       " 'auxverb (Auxiliary Verbs)',\n",
       " 'adverb (Adverbs)',\n",
       " 'conj (Conjunctions)',\n",
       " 'negate (Negations)',\n",
       " 'quanunit (quanunit)',\n",
       " 'prepend (prepend)',\n",
       " 'specart (specart)',\n",
       " 'particle (particle)',\n",
       " 'modal_pa (modal_pa)',\n",
       " 'general_pa (general_pa)',\n",
       " 'compare (Comparisons)',\n",
       " 'interrog (Interrogatives)',\n",
       " 'number (Numbers)',\n",
       " 'quant (Quantifiers)',\n",
       " 'tensem (tensem)',\n",
       " 'focuspast (Past Focus)',\n",
       " 'focuspresent (Present Focus)',\n",
       " 'focusfuture (Future Focus)',\n",
       " 'progm (progm)',\n",
       " 'affect (Affect)',\n",
       " 'posemo (Positive Emotions)',\n",
       " 'negemo (Negative Emotions)',\n",
       " 'anx (Anx)',\n",
       " 'anger (Anger)',\n",
       " 'sad (Sad)',\n",
       " 'social (Social)',\n",
       " 'family (Family)',\n",
       " 'friend (Friends)',\n",
       " 'female (Female)',\n",
       " 'male (Male)',\n",
       " 'cogproc (Cognitive Processes)',\n",
       " 'insight (Insight)',\n",
       " 'cause (Causal)',\n",
       " 'discrep (Discrepancies)',\n",
       " 'tentat (Tentative)',\n",
       " 'certain (Certainty)',\n",
       " 'differ (Differentiation)',\n",
       " 'percept (Perceptual Processes)',\n",
       " 'see (See)',\n",
       " 'hear (Hear)',\n",
       " 'feel (Feel)',\n",
       " 'bio (Biological Processes)',\n",
       " 'body (Body)',\n",
       " 'health (Health)',\n",
       " 'sexual (Sexual)',\n",
       " 'ingest (Ingest)',\n",
       " 'drives (Drives)',\n",
       " 'affiliation (Affiliation)',\n",
       " 'achieve (Achievement)',\n",
       " 'power (Power)',\n",
       " 'reward (Reward)',\n",
       " 'risk (Risk)',\n",
       " 'relativ (Relativity)',\n",
       " 'motion (Motion)',\n",
       " 'space (Space)',\n",
       " 'time (Time)',\n",
       " 'work (Work)',\n",
       " 'leisure (Leisure)',\n",
       " 'home (Home)',\n",
       " 'money (Money)',\n",
       " 'relig (Religion)',\n",
       " 'death (Death)',\n",
       " 'informal (Informal Language)',\n",
       " 'swear (Swear)',\n",
       " 'netspeak (Netspeak)',\n",
       " 'assent (Assent)',\n",
       " 'nonflu (Nonfluencies)',\n",
       " 'filler (Filler Words)']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# psychological meaningful categories in LIWC\n",
    "category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20307a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['liwc_sentiment'] = [[] for _ in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "330d7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negemo (Negative Emotions) for negative sentiment & posemo (Positive Emotions) for positive sentiment\n",
    "for i in range(len(df['msg_token'])):\n",
    "    for j in range(len(df['msg_token'][i])):\n",
    "        try:\n",
    "            if 'negemo (Negative Emotions)' in parse[df['msg_token'][i][j]]:\n",
    "                df['liwc_sentiment'][i].append('negemo (Negative Emotions)')\n",
    "            elif 'posemo (Positive Emotions)' in parse[df['msg_token'][i][j]]:\n",
    "                df['liwc_sentiment'][i].append('posemo (Positive Emotions)')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1caab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liwc_sentiment_label'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c1fbadf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harrison\\AppData\\Local\\Temp\\ipykernel_33788\\1096580149.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['liwc_sentiment_label'][i] = 'neutral'\n",
      "C:\\Users\\Harrison\\AppData\\Local\\Temp\\ipykernel_33788\\1096580149.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['liwc_sentiment_label'][i] = liwc_label\n"
     ]
    }
   ],
   "source": [
    "# select the most frequent sentiment in each message. If no sentiment labeled by liwc, label it as 'neutral'\n",
    "from collections import Counter\n",
    " \n",
    "def most_frequent(List):\n",
    "    occurence_count = Counter(List)\n",
    "    return occurence_count.most_common(1)[0][0]\n",
    "   \n",
    "for i in range(len(df['liwc_sentiment'])):\n",
    "    if len(df['liwc_sentiment'][i]) != 0:\n",
    "        liwc_label = most_frequent(df['liwc_sentiment'][i])\n",
    "        df['liwc_sentiment_label'][i] = liwc_label\n",
    "    else:\n",
    "        df['liwc_sentiment_label'][i] = 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36b13b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_label = {'negemo (Negative Emotions)':0, 'neutral':1, 'posemo (Positive Emotions)':2}\n",
    "df['liwc_sentiment_label'] = df['liwc_sentiment_label'].replace(replace_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79399a78",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "017f710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.32      0.40      1943\n",
      "           1       0.69      0.59      0.64      3267\n",
      "           2       0.26      0.60      0.36       959\n",
      "\n",
      "    accuracy                           0.51      6169\n",
      "   macro avg       0.50      0.50      0.47      6169\n",
      "weighted avg       0.58      0.51      0.52      6169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "y_true = df['sentiment_label'].tolist()\n",
    "y_pred = df['liwc_sentiment_label'].tolist()\n",
    "\n",
    "# 生成分类报告\n",
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f2f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641e44c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367937b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d044f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790c53a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
